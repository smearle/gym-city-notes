@inproceedings{socher2011parsing,
  title={Parsing natural scenes and natural language with recursive neural networks},
  author={Socher, Richard and Lin, Cliff C and Manning, Chris and Ng, Andrew Y},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={129--136},
  year={2011}
}

@article{singhal2014review,
  title={A review paper of navigation and pathfinding using mobile cellular automata},
  author={Singhal, Priyata and Kundra, Harish},
  journal={Int. J. Adv. Comput. Sci. Commun. Eng.(IJACSCE)},
  volume={2},
  pages={43--50},
  year={2014}
}

@inproceedings{oh2017zero,
  title={Zero-shot task generalization with multi-task deep reinforcement learning},
  author={Oh, Junhyuk and Singh, Satinder and Lee, Honglak and Kohli, Pushmeet},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2661--2670},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{daadaa2011decontamination,
  title={Decontamination with temporal immunity by mobile cellular automata},
  author={Daadaa, Yassine and Flocchini, Paola and Zaguia, Nejib},
  booktitle={Proceedings of the International Conference on Scientific Computing (CSC)},
  pages={1},
  year={2011},
  organization={The Steering Committee of The World Congress in Computer Science, Computer~…}
}

@incollection{behring2001algorithm,
  title={An algorithm for robot path planning with cellular automata},
  author={Behring, C and Bracho, M and Castro, M and Moreno, JA},
  booktitle={Theory and practical issues on cellular automata},
  pages={11--19},
  year={2001},
  publisher={Springer}
}

@article{hu2019hierarchical,
  title={Hierarchical decision making by generating and following natural language instructions},
  author={Hu, Hengyuan and Yarats, Denis and Gong, Qucheng and Tian, Yuandong and Lewis, Mike},
  journal={arXiv preprint arXiv:1906.00744},
  year={2019}
}

@incollection{rosenstiehl1972intelligent,
title = "Intelligent Graphs: Networks of Finite Automata Capable of Solving Graph Problems",
editor = "RONALD C. READ",
booktitle = "Graph Theory and Computing",
publisher = "Academic Press",
pages = "219 - 265",
year = "1972",
isbn = "978-1-4832-3187-7",
doi = "https://doi.org/10.1016/B978-1-4832-3187-7.50019-2",
url = "http://www.sciencedirect.com/science/article/pii/B9781483231877500192",
author = "P. Rosenstiehl and J.R. Fiksel and A. Holliger"
}

@incollection{tsompanas2016cellular,
  title={Cellular automata models simulating slime mould computing},
  author={Tsompanas, Michail-Antisthenis I and Sirakoulis, Georgios Ch and Adamatzky, Andrew},
  booktitle={Advances in Physarum Machines},
  pages={563--594},
  year={2016},
  publisher={Springer}
}

@article{adamatzky2012slime,
  title={Slime mold solves maze in one pass, assisted by gradient of chemo-attractants},
  author={Adamatzky, Andrew},
  journal={IEEE transactions on nanobioscience},
  volume={11},
  number={2},
  pages={131--134},
  year={2012},
  publisher={IEEE}
}

@article{adamatzky2010road,
  title={Road planning with slime mould: if Physarum built motorways it would route M6/M74 through Newcastle},
  author={Adamatzky, Andrew and Jones, Jeff},
  journal={International Journal of Bifurcation and Chaos},
  volume={20},
  number={10},
  pages={3065--3084},
  year={2010},
  publisher={World Scientific}
}

@article{parascandolo2017taming,
	title = {Taming the Waves: Sine as Activation Function in Deep Neural Networks},
	abstract = {Most deep neural networks use non-periodic and monotonic—or at least quasiconvex— activation functions. While sinusoidal activation functions have been successfully used for speciﬁc applications, they remain largely ignored and regarded as difﬁcult to train. In this paper we formally characterize why these networks can indeed often be difﬁcult to train even in very simple scenarios, and describe how the presence of inﬁnitely many and shallow local minima emerges from the architecture. We also provide an explanation to the good performance achieved on a typical classiﬁcation task, by showing that for several network architectures the presence of the periodic cycles is largely ignored when the learning is successful. Finally, we show that there are non-trivial tasks—such as learning algorithms—where networks using sinusoidal activations can learn faster than more established monotonic functions.},
	language = {en},
	author = {Parascandolo, Giambattista and Huttunen, Heikki and Virtanen, Tuomas},
	year = {2017},
	pages = {12},
	file = {Parascandolo et al. - 2017 - TAMING THE WAVES SINE AS ACTIVATION FUNCTION IN D.pdf:/home/sme/Zotero/storage/SDJH5LMQ/Parascandolo et al. - 2017 - TAMING THE WAVES SINE AS ACTIVATION FUNCTION IN D.pdf:application/pdf}
}

@article{gaier2019weight,
  title={Weight Agnostic Neural Networks},
  author={Gaier, Adam and Ha, David},
  journal={arXiv preprint arXiv:1906.04358},
  year={2019}
}

@inproceedings{hagg2017evolving,
  title={Evolving parsimonious networks by mixing activation functions},
  author={Hagg, Alexander and Mensing, Maximilian and Asteroth, Alexander},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={425--432},
  year={2017},
  organization={ACM}
}

@inproceedings{kim2016deeply,
  title={Deeply-recursive convolutional network for image super-resolution},
  author={Kim, Jiwon and Kwon Lee, Jung and Mu Lee, Kyoung},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1637--1645},
  year={2016}
}
@inproceedings{tai2017image,
  title={Image super-resolution via deep recursive residual network},
  author={Tai, Ying and Yang, Jian and Liu, Xiaoming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3147--3155},
  year={2017}
}
@article{bieberich2002recurrent,
  title={Recurrent fractal neural networks: a strategy for the exchange of local and global information processing in the brain},
  author={Bieberich, Erhard},
  journal={Biosystems},
  volume={66},
  number={3},
  pages={145--164},
  year={2002},
  publisher={Elsevier}
}

@article{larsson2016fractalnet,
  title={Fractalnet: Ultra-deep neural networks without residuals},
  author={Larsson, Gustav and Maire, Michael and Shakhnarovich, Gregory},
  journal={arXiv preprint arXiv:1605.07648},
  year={2016}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{stanley2002evolving,
  title={Evolving neural networks through augmenting topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  journal={Evolutionary computation},
  volume={10},
  number={2},
  pages={99--127},
  year={2002},
  publisher={MIT Press}
}

@article{stanley2009hypercube,
  title={A hypercube-based encoding for evolving large-scale neural networks},
  author={Stanley, Kenneth O and D'Ambrosio, David B and Gauci, Jason},
  journal={Artificial life},
  volume={15},
  number={2},
  pages={185--212},
  year={2009},
  publisher={MIT Press}
}

@article{chua1988cellular,
  title={Cellular neural networks: Theory},
  author={Chua, Leon O and Yang, Lin},
  journal={IEEE Transactions on circuits and systems},
  volume={35},
  number={10},
  pages={1257--1272},
  year={1988},
  publisher={IEEE}
}

@inproceedings{woolley2010evolving,
  title={Evolving a single scalable controller for an octopus arm with a variable number of segments},
  author={Woolley, Brian G and Stanley, Kenneth O},
  booktitle={International Conference on Parallel Problem Solving from Nature},
  pages={270--279},
  year={2010},
  organization={Springer}
}

@article{wang2018nervenet,
  title={Nervenet: Learning structured policy with graph neural networks},
  author={Wang, Tingwu and Liao, Renjie and Ba, Jimmy and Fidler, Sanja},
  year={2018}
}

@inproceedings{silver2007reinforcement,
  title={Reinforcement Learning of Local Shape in the Game of Go.},
  author={Silver, David and Sutton, Richard S and M{\"u}ller, Martin},
  booktitle={IJCAI},
  volume={7},
  pages={1053--1058},
  year={2007}
}

@article{FM660,
	author = {Ted Friedman},
	title = {The Semiotics of SimCity},
	journal = {First Monday},
	volume = {4},
	number = {4},
	year = {1999},
	keywords = {},
	abstract = {When does a game cease to be a game? Is it when the computer feels like an organic extension of your consciousness or when you may feel like an extension of the computer itself? This paper explores SimCity and its significance as a simulator not only of reality but consciousness. Computer gaming is essentially process of demystification, discovering how software is organized for a certain set of goals and actions.},
	issn = {13960466},	doi = {10.5210/fm.v4i4.660},
	url = {https://journals.uic.edu/ojs/index.php/fm/article/view/660}
}

@article{wells2011new,
  title={New Games of Life: Cellular Automata and Subsurface Discourses in SimCity},
  author={Wells, Matthew},
  year={2011}
}
@book{griffeath2003new,
  title={New Constructions in Cellular Automata},
  author={Griffeath, D. and Moore, C. and Moore, D.C.S.P.A.C. and Santa Fe Institute},
  isbn={9780195137187},
  lccn={2003043870},
  series={Proceedings volume in the Santa Fe Institute studies in the sciences of complexity},
  url={https://books.google.ca/books?id=M3g8DwAAQBAJ},
  year={2003},
  publisher={Oxford University Press}
}

@article{larsson2018fractalnet,
  author    = {Gustav Larsson and
               Michael Maire and
               Gregory Shakhnarovich},
  title     = {FractalNet: Ultra-Deep Neural Networks without Residuals},
  journal   = {CoRR},
  volume    = {abs/1605.07648},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.07648},
  archivePrefix = {arXiv},
  eprint    = {1605.07648},
  timestamp = {Mon, 13 Aug 2018 16:49:03 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LarssonMS16a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vinyals2017starcraft,
  author    = {Oriol Vinyals and
               Timo Ewalds and
               Sergey Bartunov and
               Petko Georgiev and
               Alexander Sasha Vezhnevets and
               Michelle Yeo and
               Alireza Makhzani and
               Heinrich K{\"{u}}ttler and
               John Agapiou and
               Julian Schrittwieser and
               John Quan and
               Stephen Gaffney and
               Stig Petersen and
               Karen Simonyan and
               Tom Schaul and
               Hado van Hasselt and
               David Silver and
               Timothy P. Lillicrap and
               Kevin Calderone and
               Paul Keet and
               Anthony Brunasso and
               David Lawrence and
               Anders Ekermo and
               Jacob Repp and
               Rodney Tsing},
  title     = {StarCraft {II:} {A} New Challenge for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1708.04782},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.04782},
  archivePrefix = {arXiv},
  eprint    = {1708.04782},
  timestamp = {Mon, 13 Aug 2018 16:47:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-04782},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{vinyals2019alphastar,
  title="{AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}",
  author={Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojciech M. and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Agapiou, John and Oh, Junhyuk and Dalibard, Valentin and Choi, David and Sifre, Laurent and Sulsky, Yury and Vezhnevets, Sasha and Molloy, James and Cai, Trevor and Budden, David and Paine, Tom and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Pohlen, Toby and Wu, Yuhuai and Yogatama, Dani and Cohen, Julia and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Apps, Chris and Kavukcuoglu, Koray and Hassabis, Demis and Silver, David},
  howpublished={\url{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}},
  year={2019}
}

@article{silver2016alphagozero,
  abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses 'value networks' to evaluate board positions and 'policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8 percent winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
  added-at = {2016-05-21T09:09:48.000+0200},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/flint63},
  doi = {10.1038/nature16961},
  file = {Nature online:2016/SilverHuangEtAl16nature.pdf:PDF},
  groups = {public},
  interhash = {48430c7891aaf9fe2582faa8f5d076c1},
  intrahash = {9e987f58d895c490144693139cbc90c7},
  issn = {0028-0836},
  journal = {Nature},
  keywords = {01614 paper ai google learn algorithm},
  month = {jan},
  number = 7587,
  pages = {484--489},
  timestamp = {2018-04-16T12:03:12.000+0200},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  username = {flint63},
  volume = 529,
  year = 2016
}

@book{batty1994fractalcities,
 author = {Batty, Michael and Longley, Paul},
 title = {Fractal Cities: A Geometry of Form and Function},
 year = {1994},
 isbn = {0-12-455570-5},
 publisher = {Academic Press Professional, Inc.},
 address = {San Diego, CA, USA},
} 

@article{white1993automata,
author = {R White and G Engelen},
title ={Cellular Automata and Fractal Urban Form: A Cellular Modelling Approach to the Evolution of Urban Land-Use Patterns},
journal = {Environment and Planning A: Economy and Space},
volume = {25},
number = {8},
pages = {1175-1199},
year = {1993},
doi = {10.1068/a251175},

URL = { 
        https://doi.org/10.1068/a251175
    
},
eprint = { 
        https://doi.org/10.1068/a251175
    
}
,
    abstract = { Cellular automata belong to a family of discrete, connectionist techniques being used to investigate fundamental principles of dynamics, evolution, and self-organization. In this paper, a cellular automaton is developed to model the spatial structure of urban land use over time. For realistic parameter values, the model produces fractal or bifractal land-use structures for the urbanized area and for each individual land-use type. Data for a set of US cities show that they have very similar fractal dimensions. The cellular approach makes it possible to achieve a high level of spatial detail and realism and to link the results directly to general theories of structural evolution. }
}

@article{aburas2016urbangrowth,
title = "The simulation and prediction of spatio-temporal urban growth trends using cellular automata models: A review",
journal = "International Journal of Applied Earth Observation and Geoinformation",
volume = "52",
pages = "380 - 389",
year = "2016",
issn = "0303-2434",
doi = "https://doi.org/10.1016/j.jag.2016.07.007",
url = "http://www.sciencedirect.com/science/article/pii/S0303243416301143",
author = "Maher Milad Aburas and Yuek Ming Ho and Mohammad Firuz Ramli and Zulfa Hanan Ash’aari",
keywords = "Simulation, Prediction, Urban growth, Spatio-temporal, Cellular automata",
abstract = "In recent years, several types of simulation and prediction models have been used within a GIS environment to determine a realistic future for urban growth patterns. These models include quantitative and spatio-temporal techniques that are implemented to monitor urban growth. The results derived through these techniques are used to create future policies that take into account sustainable development and the demands of future generations. The aim of this paper is to provide a basis for a literature review of urban Cellular Automata (CA) models to find the most suitable approach for a realistic simulation of land use changes. The general characteristics of simulation models of urban growth and urban CA models are described, and the different techniques used in the design of these models are classified. The strengths and weaknesses of the various models are identified based on the analysis and discussion of the characteristics of these models. The results of the review confirm that the CA model is one of the strongest models for simulating urban growth patterns owing to its structure, simplicity, and possibility of evolution. Limitations of the CA model, namely weaknesses in the quantitative aspect, and the inability to include the driving forces of urban growth in the simulation process, may be minimized by integrating it with other quantitative models, such as via the Analytic Hierarchy Process (AHP), Markov Chain and frequency ratio models. Realistic simulation can be achieved when socioeconomic factors and spatial and temporal dimensions are integrated in the simulation process."
}


@ARTICLE{mnih2016a2c,
   author = {{Mnih}, V. and {Puigdom{\`e}nech Badia}, A. and {Mirza}, M. and 
	{Graves}, A. and {Lillicrap}, T.~P. and {Harley}, T. and {Silver}, D. and 
	{Kavukcuoglu}, K.},
    title = "{Asynchronous Methods for Deep Reinforcement Learning}",
  journal = {arXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1602.01783},
 keywords = {Computer Science - Machine Learning},
     year = 2016,
    month = feb,
   adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160201783M},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

